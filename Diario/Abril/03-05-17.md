### 03-05-17

## Extraindo informações do vídeo

Nos últimos dias, tive alguns contratempos com as frames enviadas pelo Eliezyer, pois embora os nomes das frames tenham vindo 
enumeradas em ordem crescente, conforme requerido para juntá-las e formar um vídeo, todas os nomes terminavam em "_1_0". Como era 
inviável mudar manualmente os nomes de 50290 arquivos, procurei por formas de realizar isso automaticamente. Após ~~muitas~~ algumas 
tentativas, consegui remover todos os "_1_0" utilizando o comando _rename_, no Ubuntu. Para gerar o vídeo, utilizei o Virtual Dub,
 no Windows, que provavelmente não fez qualquer tipo de compressão de informações e me resultou em um vídeo de 43,1GB, com uma 
 qualidade não muito boa, como pode ser visto na figura abaixo:
 
 ** inserir imagem **

Havia deixado de lado o vídeo, pois constatei que as frames não foram obtidas a uma mesma taxa, além de haver frames ligeiramente fora de ordem (informações obtidas 
pelo arquivo contendo os timestamps de cada frame)e pensei que isso pudesse invalidar a precisão da classificação gerada a partir do vídeo. 
Porém, ontem resolvi gerar o vídeo com uma taxa de frames por segundo (fps) 
constante (embora não o fosse) igual a 20, já que para 2508,53s de gravação haviam 50290 frames. Para cada tempo que inferi que
o animal dormia ou acordava, bastava multiplicar o instante em segundos por 20, que era possível saber em qual frame aproximadamente 
o animal mudava de estado. Com as frames de mudança de estado, bastou procurar os timestamps associados a essas frames. 
Com isso, já sabemos, por observação do animal, a partir de que ponto o sinal passava a representar um estado diferente, o que 
será bastante útil para validarmos nosso modelo classificador, pois saberemos que de fato o rato estava acordado/dormindo num dado 
intervalo de tempo.

Os intervalos que classifiquei ao assistir ao vídeo foram os da figura abaixo (entre as retas vermelhas, entre as retas amarelas e entre 
as retas verdes):

![](https://github.com/ianamccs/OpenLabBook-Iana/blob/master/Imagens/intervalos.png)

No intervalo entre as retas amarelas tive dúvida se o animal realmente dormia, pois, embora mantivesse o corpo em repouso, a cabeça fazia 
leves movimentos de tempos em tempos. Pretendo mostrar o trecho em questão para o Cleiton na sexta-feira, 05/05.

## Processando o sinal

Com relação ao sinal que vinha trabalhando, gerei blocos de um número fixo de segundos do sinal suavizado. Para cada bloco peguei 
o valor máximo, e construí um vetor max_blocos, que contém os máximos a cada N segundos de sinal. 

O sinal contendo os valores máximos para blocos de 30s pode ser visto na figura abaixo:

![](https://github.com/ianamccs/OpenLabBook-Iana/blob/master/Imagens/maxblocos30.png)

Ao fazer o histograma desse vetor de máximos dos blocos, esperávamos uma distribuição bimodal, que apresentasse a classe 
DORMINDO com uma média e desvio padrão e 
a classe ACORDADO com uma média mais afastada e desvio padrão. No entanto, fomos surpreendidos pelo seguinte histograma:

![](https://github.com/ianamccs/OpenLabBook-Iana/blob/master/Imagens/hist.png)

De fato, olhando para o sinal dos máximos, percebemos intensas variações no período acordado, o que acaba por gerar muitos pontos 
de baixa amplitude, mesmo nessa fase.

Embora a análise estatística do problema venha servindo para uma análise exploratória dos dados, ainda não consegui visualizar 
como poderemos partir dessas informações para um separador entre as classes, haja vista que, conforme visto no histograma, não 
há uma distribuiço clara que abranja as duas classes. Juntando os trechos classificados como ACORDADO em um sinal e os trechos 
DORMINDO em um outro sinal, temos o seguinte:

![](https://github.com/ianamccs/OpenLabBook-Iana/blob/master/Imagens/classes.png)


Lembrando que não há certeza de que o animal estava dormindo no trecho central da curva azul.

